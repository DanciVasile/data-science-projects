# ğŸ“Š Data Science Projects

> A collection of end-to-end data science projects â€” from exploratory analysis to model training and evaluation.

---

### Tech Stack

![Python](https://img.shields.io/badge/Python-â‰¥3.14-3776AB?logo=python&logoColor=white)
![pandas](https://img.shields.io/badge/pandas-â‰¥3.0.1-150458?logo=pandas&logoColor=white)
![NumPy](https://img.shields.io/badge/NumPy-â‰¥2.4.2-013243?logo=numpy&logoColor=white)
![scikit-learn](https://img.shields.io/badge/scikit--learn-â‰¥1.8.0-F7931E?logo=scikit-learn&logoColor=white)
![XGBoost](https://img.shields.io/badge/XGBoost-â‰¥3.2.0-FF6600?logo=xgboost&logoColor=white)
![Keras](https://img.shields.io/badge/Keras-â‰¥3.13.2-D00000?logo=keras&logoColor=white)
![Matplotlib](https://img.shields.io/badge/Matplotlib-â‰¥3.10.8-11557C?logoColor=white)
![Seaborn](https://img.shields.io/badge/Seaborn-â‰¥0.13.2-444876?logoColor=white)
![Jupyter](https://img.shields.io/badge/Jupyter-â‰¥1.1.1-F37626?logo=jupyter&logoColor=white)
![FastAPI](https://img.shields.io/badge/FastAPI-â‰¥0.133.1-009688?logo=fastapi&logoColor=white)
![Streamlit](https://img.shields.io/badge/Streamlit-â‰¥1.19.0-FF4B4B?logo=streamlit&logoColor=white)
![License](https://img.shields.io/badge/License-MIT-green)

---

## ğŸ“ Projects

| # | Project | Description | Status |
|---|---------|-------------|--------|
| 1 | [ğŸ  House Price Prediction](house_price_prediction/) | Regression on the Ames Housing dataset (2,930 samples, 82 features). Linear Regression vs Random Forest with full sklearn pipeline. | âœ… Complete |
| 2 | [ğŸ’³ Loan Default Prediction](loan_default_prediction/) | Binary classification on loan repayment data. | ğŸ”œ Coming soon |
| 3 | ğŸ©º Heart Disease Classification | Multi-class classification on clinical data. | ğŸ“‹ Planned |
| 4 | ğŸ›’ Customer Churn Prediction | Churn analysis with gradient boosting and feature importance. | ğŸ“‹ Planned |
| 5 | ğŸ“ Sentiment Analysis (NLP) | Text classification with deep learning (Keras). | ğŸ“‹ Planned |
| â€¦ | *More projects added over time* | | |

---

## ğŸ“‚ Repository Structure

```
data-science-projects/
â”œâ”€â”€ pyproject.toml                  # Shared dependencies (managed by uv)
â”œâ”€â”€ init.ps1                        # Run once after cloning (installs deps + kernel)
â”œâ”€â”€ setup.ps1                       # New-project generator script
â”œâ”€â”€ create_notebook.py              # EDA notebook template generator
â”œâ”€â”€ README.md
â”œâ”€â”€ LICENSE
â”‚
â”œâ”€â”€ house_price_prediction/
â”‚   â”œâ”€â”€ data/ames-housing.csv
â”‚   â”œâ”€â”€ docs/data-dictionary.md
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ linear_regression.pkl
â”‚   â”‚   â””â”€â”€ random_forest.pkl
â”‚   â”œâ”€â”€ notebooks/exploration.ipynb
â”‚   â”œâ”€â”€ reports/figures/
â”‚   â”œâ”€â”€ src/train.py
â”‚   â””â”€â”€ README.md
â”‚
â”œâ”€â”€ loan_default_prediction/
â”‚   â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ notebooks/exploration.ipynb
â”‚   â”œâ”€â”€ reports/figures/
â”‚   â”œâ”€â”€ src/
â”‚   â””â”€â”€ README.md
â”‚
â”œâ”€â”€ <project_3>/                    # Same structure for every project
â”‚   â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ notebooks/exploration.ipynb
â”‚   â”œâ”€â”€ reports/figures/
â”‚   â”œâ”€â”€ src/train.py
â”‚   â””â”€â”€ README.md
â”‚
â””â”€â”€ ...
```

Every project follows the same layout: `data/` â†’ `notebooks/` (EDA) â†’ `src/` (training) â†’ `models/` (artefacts) â†’ `reports/figures/` (plots).

---

## ğŸ› ï¸ Setup

### Prerequisites â€” install uv (recommended)

This repo uses [**uv**](https://docs.astral.sh/uv/) as the Python package manager.  
uv is **10â€“100Ã— faster** than pip, handles virtual environments automatically, and locks exact dependency versions for full reproducibility via `uv.lock`.

**Install uv:**

```bash
# Windows (PowerShell)
powershell -ExecutionPolicy ByPass -c "irm https://astral.sh/uv/install.ps1 | iex"

# macOS / Linux
curl -LsSf https://astral.sh/uv/install.sh | sh
```

> See the [uv installation docs](https://docs.astral.sh/uv/getting-started/installation/) for more options.

### Clone & install

```bash
git clone https://github.com/DanciVasile/data-science-projects.git
cd data-science-projects
.\init.ps1       # installs dependencies + registers Jupyter kernel
```

The `init.ps1` script runs `uv sync` (creates `.venv`) and registers it as a Jupyter kernel named **"Data Science Projects"** so every notebook uses the correct environment out of the box.

Then navigate into any project folder and follow its README.

### Alternative (pip)

If you prefer pip over uv:

```bash
python -m venv .venv
.venv\Scripts\Activate.ps1   # Windows
pip install -e .
```

---

## ğŸ†• Starting a New Project

Two scripts automate new project creation so every project starts with the same structure and conventions:

### `setup.ps1` â€” Generate a full project folder

```powershell
mkdir my_new_project; cd my_new_project
& ..\setup.ps1
```

Creates:

```
my_new_project/
â”œâ”€â”€ data/
â”œâ”€â”€ docs/
â”œâ”€â”€ models/
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ exploration.ipynb   â† generated from EDA template
â”œâ”€â”€ reports/figures/
â””â”€â”€ src/
```

### `create_notebook.py` â€” Generate the EDA notebook only

```bash
uv run create_notebook.py notebooks       # into a subfolder
uv run create_notebook.py                  # into current directory
```

The notebook template includes 10 sections (imports, config, loading, target analysis, missing values, cleaning, univariate EDA, bivariate EDA, outlier detection, summary) with a `TASK` variable that switches between regression and classification behaviour automatically.

---

## ğŸ¤– Automated Notebook Setup

Every generated notebook comes with **two automations** so you (and anyone who clones the repo) can start working immediately â€” no manual path editing or kernel hunting.

### Automatic data path resolution

The configuration cell resolves the project's `data/` directory automatically, regardless of where the kernel's working directory is set:

| Environment | How it resolves |
|---|---|
| **VS Code** | Uses the `__vsc_ipynb_file__` variable injected by the Jupyter extension |
| **JupyterLab / Classic Jupyter** | Walks up from the kernel's CWD (which Jupyter sets to the notebook's directory) |

**All you need to do** is drop your dataset into the project's `data/` folder and set the filename:

```python
DATA_FILE = "my-dataset.csv"   # â† only thing you change
```

The full path is built automatically:

```python
DATA_PATH = PROJECT_DIR / "data" / DATA_FILE
```

### Automatic kernel selection

Notebooks are pre-configured to use the **"Data Science Projects"** kernel registered by `init.ps1`.  
After running `.\init.ps1` once, every notebook will pick up the correct `.venv` kernel automatically â€” no need to manually select an interpreter.

> **Tip:** If you open a notebook and the kernel shows "Select Kernel", just run `.\init.ps1` again to re-register it.

---

## ğŸ“„ License

This repository is licensed under the [MIT License](LICENSE).

---

<p align="center">
  Made with â¤ï¸ by <strong>Vasile-Marian Danci</strong>
  <br/><br/>
  <a href="https://github.com/DanciVasile">
    <img src="https://img.shields.io/badge/GitHub-181717?style=for-the-badge&logo=github&logoColor=white" alt="GitHub"/>
  </a>
  &nbsp;
  <a href="https://www.linkedin.com/in/vasile-danci-m/">
    <img src="https://img.shields.io/badge/LinkedIn-0A66C2?style=for-the-badge&logo=linkedin&logoColor=white" alt="LinkedIn"/>
  </a>
</p>
